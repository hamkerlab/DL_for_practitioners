{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdc71d8-931d-41cf-bdc3-6adb1b015006",
   "metadata": {},
   "source": [
    "# Tutorial 2.2. How to create a convolutional neural network (CNN)\n",
    "\n",
    "Author: [Maren Gr√∂ne](mailto:maren.groene@s2016.tu-chemnitz.de)\n",
    "\n",
    "You will notice a big overlap with the implementation from Tutorial 2.1 since the basics are always the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995c7e0",
   "metadata": {},
   "source": [
    "Check and set the available device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa2346-2ee1-4160-a9c3-5aaef5694b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print('Device is ',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c6802",
   "metadata": {},
   "source": [
    "Load and prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f154009-dfa2-4537-aae8-d4b055c48b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))])\n",
    "batch_size=4\n",
    "trainset = torchvision.datasets.MNIST(root='../Dataset/', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../Dataset/', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# list of class labels\n",
    "\n",
    "classes = trainset.classes\n",
    "print(f'Classes: {classes}')\n",
    "# number of elements\n",
    "numTrain = len(trainset)\n",
    "numTest = len(testset)\n",
    "print(f'Trainset: {numTrain} elements, Testset: {numTest} elements')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11015f13-ed06-415c-bfcd-ed8ffe74de09",
   "metadata": {},
   "source": [
    "Plot images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2cdb6-f1f1-4219-b54f-f34d51fbf1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(imges):\n",
    "    plt.figure()\n",
    "    for i in range(4):\n",
    "        img = imges[i,0]\n",
    "        img = img / 2 + 0.5 #unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.subplot(1,4,i+1)\n",
    "        plt.imshow(npimg, cmap='gray')\n",
    "    plt.show\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(images)\n",
    "\n",
    "print('Classes are: ')\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72614289-c286-49d7-a705-3f86701de016",
   "metadata": {},
   "source": [
    "## Create the convolutional neural network\n",
    "\n",
    "### The network class\n",
    "\n",
    "As before, we create a class object which inherits from the `torch.nn.Module`class to build our neural network. This includes the layer objects and the feedforward pass.\n",
    "\n",
    "#### Define the network structure\n",
    "\n",
    "We add two convolutional layers before the neural network from tutorial 1.\n",
    "\n",
    "To add a 2D-convolutional layer, we use the `nn.Conv2D()` object, which needs at least the following three parameters:\n",
    "1. Number of input channels/ feature maps (corresponds to color channels, e.g. RGB)\n",
    "2. Number of output channels / feature maps\n",
    "3. Size of the convolutional kernel as single integer or tuple.\n",
    "(for more information look in the [official PyTorch documentation](ttps://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html))\n",
    "\n",
    "As we want to process gray-scaled images, the input only has a single color channel. Therefore, the number of input channels into the first convolutional layer is $1$. We want $6$ feature maps and a kernel size of $5 \\times 5$. In contrast to defining fully-connected layers, the pixel dimensions of the image is not relevant.\n",
    "\n",
    "Creating our first convolutional layer leads to the following code line:\n",
    "\n",
    "`self.conv1 = nn.Conv2d(1,6,5)`\n",
    "\n",
    "With a similar call, we create the second convolutional layer. Here, since we defined 6 output feature maps for the previous layer, we need 6 input channels for this layer.\n",
    "\n",
    "`self.conv1 = nn.Conv2d(6,16,5)`\n",
    "\n",
    "As we want to perform a maximum pooling, we add a pooling layer with the first parameter as the size of the pooling kernel, and the second parameter as the stride of the pooling window:\n",
    "\n",
    "`self.pool = nn.MaxPool2d(2,2)`\n",
    "\n",
    "The last convolutional layer projects onto a fully connected layer where the explicit number of inputs is relevant again. The size of an image after a convolutional layer is:\n",
    "`(W-K+2P)/S+1` with input dimensions `W`, kernel size `K`, padding `P` and stride `S`. With max pooling here, it is halved again, so `((W-K+2P)/S+1)/2`. \n",
    "\n",
    "After the first convolution, the dimension is $((28-5+2*0)/1+1)/2=12$ and after the second (here abbreviated) $(12-5+1)/2=4$. The last convolutional layer has 16 feature maps. Therefore, the number of outputs equals $16 \\times 4 \\times 4$ and represents the number of inputs of the fully-connected layer. \n",
    "\n",
    "`self.fc1 = nn.Linear(16*4*4,120)`\n",
    "\n",
    "Then we add a second fully-connected layer:\n",
    "\n",
    "`self.fc2 = nn.Linear(120,84)`\n",
    "\n",
    "And the classification head with 10 output neurons:\n",
    "\n",
    "`self.fc3 = nn.Linear(84,10)`\n",
    "\n",
    "Please note that here we only define which layers we want to use in our network. The order of defining them is not important at the moment.\n",
    "\n",
    "Afterwards, the feedforward pass is defined. A new concept here is the forward pass for the convolutional layer `x = self.pool(F.relu(self.conv1(x)))` where the input is passed through the convolutional layer. Then, the activation layer ReLU is used and, afterwards, max pooling is performed. Also, the output from the convolutional layer needs to be flattened for the fully-connected layer (as the images needed to be in the previous tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21cd44-90d3-407a-9727-a057bdbdf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## define the network structure with the layers\n",
    "        self.conv1 = nn.Conv2d(1,6,5) # in_channels, out_channels, kernel_size \n",
    "        self.conv2 = nn.Conv2d(6,16,5) # in_channels,out_channels, kernel_size\n",
    "        self.pool  = nn.MaxPool2d(2,2) # kernel_size, stride\n",
    "        self.fc1   = nn.Linear(16*4*4, 120) # in_channels, out_channels\n",
    "        self.fc2   = nn.Linear(120,84) # in_channels, out_channels\n",
    "        self.fc3   = nn.Linear(84,10) # in_channels, out_channels\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## define the functionality of each layer/between the layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x,1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107db95-84d9-4245-9837-8fca1722036e",
   "metadata": {},
   "source": [
    "#### Creating the network\n",
    "Now we can simply create a new network object and assign it to the device identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a9daf-5c5b-4416-a944-026e5dfcdd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e5497-d883-484e-8c8d-e8fff01a7031",
   "metadata": {},
   "source": [
    "### Set up loss and optimizer\n",
    "We use the `CrossEntropyLoss`as loss-function on the error between the network output and the correct labels and the simple\n",
    "Stochastic-Gradient-Descend (`SGD`) optimizer.\n",
    "Please note, that the optimizer needs the parameters of our network `net.parameters()` as input to define which need to be tuned.\n",
    "\n",
    "Further available loss functions and optimizers can be found on the [official PyTorch website](https://pytorch.org/docs/stable/nn.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c6cef-8eeb-4cc5-8345-8d45b55e0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99440b4e-5ee5-4241-91d0-5421bb124947",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9dcfca-b2db-4cc4-bb52-55c8f6de7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the input data and labels\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch +1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dcff51-967f-4713-86f2-d4f4032b872d",
   "metadata": {},
   "source": [
    "After training, we save the parameters of the trained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './mnist_cnn_net.pth'\n",
    "torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ede117-4dd8-42c3-a91e-b361e05c5b9b",
   "metadata": {},
   "source": [
    "## Test the network performance\n",
    "We use the testloader object to see, how well the network will recognice the numbers in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdcf93f-1fc2-4f43-88b3-03265626b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93454ce-b165-44e9-851e-5b8fadb91b3b",
   "metadata": {},
   "source": [
    "We create a new network object and load the parameters from the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410efac3-cd14-4eeb-b14a-8d1b9790f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(path, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da716b-c13c-4dfd-94e6-3cea42dc3ddf",
   "metadata": {},
   "source": [
    "We test the first four images to see how well they work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e652f700-819f-4139-a858-625227e76e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(images)\n",
    "imshow(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3c57a-f392-4f59-9cea-d855df99c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(output, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27132b2a-fabe-4cfa-baaf-a4bbbc61a046",
   "metadata": {},
   "source": [
    "As this looks very promising, we write a loop to get the data from the testload batchwise and pass them through the network.\n",
    "\n",
    "To avoid further training and to reduce the computational costs, we deactivate the calculation of gradients with `torch.no_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da4833-f5e0-4ac0-9738-e8c508782330",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total   = 0\n",
    "\n",
    "# use no_grad as we do not want further training\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "\n",
    "        outputs = net(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f'Accuracy of the network on the test set: {100*correct // total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39ea6d",
   "metadata": {},
   "source": [
    "## Exercise: Implement a convolutional neural network for the FashionMNIST dataset\n",
    "\n",
    "Similar to the previous tutorial and exercise, implement a CNN for the FashionMNIST dataset. Experiment with layer sizes, number of epochs, number of layers, batch size and kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch and set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6691a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda36d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network layer and feedforward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network and define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa557bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network and save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d63558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
